# PruneScan - JCIA Hackathon 2025
# Tri Automatique des Prunes

Ce projet pr√©sente un syst√®me de classification d'images de prunes bas√© sur le deep learning pour trier automatiquement les prunes africaines selon leur qualit√©.

## √âquipe
- LONTSI LAMBOU Ronaldino - lontsilambou@gmail.com
- FETUE FOKO Nathanael - nathanaelfetue1237@gmail.com
- TCHIAZE FOUOSSO Romero - romerotchiazefouosso@gmail.com

## Structure du Repository
```
repository/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ african_plums_dataset/
‚îÇ   ‚îú‚îÄ‚îÄ prune.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ best_plum_model.h5
‚îî‚îÄ‚îÄ frontend/
    ‚îî‚îÄ‚îÄ [application Flutter]
```

## Guide d'ex√©cution rapide

### Backend

Le backend est impl√©ment√© sous forme de notebook Jupyter qui g√©n√®re un mod√®le entra√Æn√© (`best_plum_model.h5`).

1. **Installer les d√©pendances**:
```bash
pip install tensorflow opencv-python pandas numpy matplotlib seaborn scikit-learn tqdm jupyter
```

2. **T√©l√©charger le dataset**:
   - T√©l√©chargez le dataset depuis Kaggle: [African Plums Quality Dataset](https://www.kaggle.com/datasets/arnaudfadja/african-plums-quality-and-defect-assessment-data)
   - Placez-le dans le dossier `backend/`

3. **Ex√©cuter le notebook**:
```bash
cd backend
jupyter notebook
# Ouvrez et ex√©cutez notebook.ipynb
```

### Frontend
1. **Installation de Flutter**:
Assurez-vous que Flutter est install√© sur votre syst√®me. Si ce n'est pas le cas, suivez les instructions sur flutter.dev.
2. **Installation des d√©pendances**

```bash 
cd PruneScan
flutter pub get
```
3. **Ex√©cuter l'application Flutter**:
```bash
flutter run
```


### Mod√®le

Le c≈ìur du projet repose sur un mod√®le de classification d'images bas√© sur l'architecture **MobileNetV2**, pr√©-entra√Æn√©e sur ImageNet. Le mod√®le a √©t√© modifi√© et entra√Æn√© pour classer des images de prunes africaines selon leur qualit√© ou leurs d√©fauts.

## üîß Architecture
* **Base** : `MobileNetV2` (poids pr√©-entra√Æn√©s sur ImageNet, sans la couche de classification finale)
* **Couches personnalis√©es** :
   * `GlobalAveragePooling2D`
   * `Dense(256)` + `BatchNormalization` + `Dropout(0.6)`
   * `Dense(128)` + `BatchNormalization` + `Dropout(0.4)`
   * `Dense(nb_classes, activation='softmax')` (couche de sortie)

L'ensemble du mod√®le est r√©gularis√© avec `L1/L2` pour √©viter l'overfitting.

## ‚öôÔ∏è Pr√©traitement et Augmentation
Les donn√©es sont charg√©es avec `ImageDataGenerator`, incluant :
* Normalisation (`rescale=1./255`)
* Augmentations : rotation, translation, zoom, flips horizontaux
* Validation split automatique (20%)

## üìâ Fonction de perte
Utilisation de la **Focal Loss** (avec `gamma=2.0`) pour mieux g√©rer le d√©s√©quilibre des classes, en concentrant l'apprentissage sur les classes minoritaires.

## ‚öñÔ∏è Gestion du d√©s√©quilibre des classes
Des **poids de classes** sont calcul√©s dynamiquement pour renforcer l'importance des classes sous-repr√©sent√©es (`bruised`, `cracked`, etc.), en utilisant une pond√©ration ajust√©e √† l'aide d'une exponentiation (`^1.5`) sur les classes les plus rares.

## üß† Strat√©gie d'entra√Ænement
L'entra√Ænement est r√©alis√© en trois phases :

1. **Entra√Ænement initial**
   * Couches personnalis√©es uniquement (MobileNetV2 gel√©)
   * `75 epochs`
   * Optimiseur : `Adam`, avec LR r√©duit
   * Callbacks : `EarlyStopping`, `ReduceLROnPlateau`, `ModelCheckpoint`

2. **Fine-tuning partiel**
   * D√©gel des **30 derni√®res couches** de MobileNetV2
   * Recompilation du mod√®le
   * `35 epochs`

3. **Fine-tuning complet**
   * D√©gel complet de MobileNetV2
   * Recompilation finale
   * `25 epochs`

Chaque phase conserve les meilleurs poids gr√¢ce √† `ModelCheckpoint`.

## üìä √âvaluation et m√©triques
Pendant l'entra√Ænement, les m√©triques suivantes sont surveill√©es :
* `Accuracy`
* `AUC`
* `Precision`
* `Recall`

Un graphique est g√©n√©r√© pour visualiser les **poids de classe** appliqu√©s, illustrant leur importance dans le traitement du d√©s√©quilibre.

## üíæ Mod√®le final
Le meilleur mod√®le est sauvegard√© automatiquement sous le nom : `best_plum_model.h5`



## R√©sultats obtenus

Notre mod√®le a atteint d'excellentes performances sur l'ensemble de test:

### M√©triques globales:
- **Accuracy**: 0.8419
- **AUC**: 0.9712
- **Precision**: 0.8641
- **Recall**: 0.8168

### Pr√©cision par classe:
- **bruised**: 0.7222
- **cracked**: 0.6486
- **rotten**: 0.9792
- **spotted**: 0.6531
- **unaffected**: 0.9267
- **unripe**: 0.9189

### √âchantillons correctement classifi√©s:
- **bruised**: 39 sur 48 √©chantillons
- **cracked**: 24 sur 24 √©chantillons
- **rotten**: 94 sur 108 √©chantillons
- **spotted**: 96 sur 114 √©chantillons
- **unaffected**: 215 sur 259 √©chantillons
- **unripe**: 102 sur 124 √©chantillons

## D√©tails du projet

### Compr√©hension du probl√®me

Notre projet r√©pond au d√©fi du tri automatique des prunes africaines. Les challenges sp√©cifiques incluent:
- La d√©tection pr√©cise de 6 cat√©gories diff√©rentes de prunes (saines, non m√ªres, tachet√©es, pourries, meurtries, fissur√©es)
- Le d√©s√©quilibre important entre les classes (certains d√©fauts √©tant rares dans le dataset)
- La n√©cessit√© d'un mod√®le suffisamment l√©ger pour √™tre d√©ploy√© dans un environnement de production

### Mod√®le choisi

Nous avons opt√© pour une architecture bas√©e sur **MobileNetV2** pour les raisons suivantes:
-Nous avons choisi MobileNetV2 comme mod√®le de base pour le transfert learning car il a d√©j√† √©t√© entra√Æn√© sur un dataset de classification de fruits contenant 14 classes, dont celle des prunes. Selon l‚Äôarticle "Fruit Image Classification Model Based on MobileNetV2 with Deep Transfer Learning Technique" (publi√© le 19 janvier 2023), MobileNetV2 a surpass√© des mod√®les populaires tels que ResNet, InceptionV3, AlexNet et VGG16 en termes de taux de pr√©cision, justifiant ainsi son efficacit√© pour ce type de t√¢che.
- Performances √©lev√©es dans les t√¢ches de classification d'images
- Efficacit√© computationnelle (adapt√© pour le d√©ploiement sur des appareils √† ressources limit√©es)
- 
Notre architecture du modele comprend:
- MobileNetV2 comme mod√®le de base
- Couches suppl√©mentaires personnalis√©es avec r√©gularisation L1-L2
- Normalisation par lots et dropout pour r√©duire le surapprentissage
- Fonction de perte Focal Loss pour g√©rer le d√©s√©quilibre des classes

### M√©thodologie

#### Pr√©traitement des donn√©es
- Redimensionnement des images √† 324√ó324 pixels
- Normalisation des valeurs de pixel (0-1)
- Augmentation de donn√©es agressive pour les classes minoritaires (rotation, translation, cisaillement, zoom, retournement, variation de luminosit√©)

#### Division des donn√©es
- 70% pour l'entra√Ænement
- 15% pour la validation
- 15% pour le test
- Division stratifi√©e pour maintenir la distribution des classes

#### Gestion du d√©s√©quilibre
- Surrepr√©sentation des classes minoritaires dans l'ensemble d'entra√Ænement
- Pond√©ration des classes avec une puissance de 1.5 pour les classes 'bruised' et 'cracked'
- Focal Loss avec gamma=2.0 pour se concentrer sur les exemples difficiles

#### Strat√©gie d'entra√Ænement faite
- Entra√Ænement en trois phases:
  1. Entra√Ænement initial des couches sup√©rieures (75 √©poques)
  2. Premier fine-tuning avec les 30 derni√®res couches de MobileNetV2 d√©gel√©es (35 √©poques)
  3. Deuxi√®me fine-tuning avec toutes les couches d√©gel√©es (25 √©poques)
- Utilisation de callbacks pour:
  - Sauvegarde du meilleur mod√®le (ModelCheckpoint)
  - Arr√™t pr√©coce pour √©viter le surapprentissage (EarlyStopping)
  - R√©duction du taux d'apprentissage en plateau (ReduceLROnPlateau)

## Contact

Pour toute question concernant ce projet, veuillez contacter les membres de l'√©quipe aux adresses email fournies ci-dessus.
